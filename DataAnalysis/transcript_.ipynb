{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "id": "bf3529ae-7e71-494c-a86a-6013c0a1f434",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 3,
   "id": "bf3529ae-7e71-494c-a86a-6013c0a1f434",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'AudioSegment' has no attribute 'from_m4a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[0;32m----> 3\u001b[0m song \u001b[38;5;241m=\u001b[39m \u001b[43mAudioSegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_m4a\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/fhuq/Documents/Zoom/noteeline user study/P11/audio1808392276.m4a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# PyDub handles time in milliseconds\u001b[39;00m\n\u001b[1;32m      6\u001b[0m ten_minutes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'AudioSegment' has no attribute 'from_m4a'"
     ]
    }
   ],
>>>>>>> Stashed changes
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "song = AudioSegment.from_m4a(\"/Users/fhuq/Documents/Zoom/noteeline user study/P11/audio1808392276.m4a\")\n",
    "\n",
    "# PyDub handles time in milliseconds\n",
    "ten_minutes = 10 * 60 * 1000\n",
    "\n",
    "first_10_minutes = song[:ten_minutes]\n",
    "\n",
    "first_10_minutes.export(\"good_morning_10.m4a\", format=\"m4a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b390aa-8cc2-4626-9566-97dfaab1cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY']=\"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\"\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file = open(\"/Users/fhuq/Documents/Zoom/noteeline user study/P11/audio1808392276.m4a\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "  file=audio_file,\n",
    "  model=\"whisper-1\",\n",
    "  response_format=\"verbose_json\",\n",
    "  timestamp_granularities=[\"segment\"]\n",
    ")\n",
    "\n",
    "print(transcript.words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce2e091-8cce-4007-aaa6-3743d2749847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Split the audio file into chunks and export each chunk\n",
    "def split_audio(file_path, chunk_length_ms=600000):  # default chunk length is 10 minutes\n",
    "    audio = AudioSegment.from_mp3(file_path)\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(audio), chunk_length_ms):\n",
    "        chunk = audio[i:i+chunk_length_ms]\n",
    "        chunk_name = f\"chunk_{i//chunk_length_ms}.mp3\"\n",
    "        chunk.export(chunk_name, format=\"mp3\")\n",
    "        chunks.append(chunk_name)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Process each chunk (this is where you'd send it to the API for transcription)\n",
    "def process_chunks(chunks):\n",
    "    results = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        # Assuming you have a function 'transcribe' that sends the chunk to the API and gets the result\n",
    "        result = transcribe(chunk)\n",
    "        results.append(result)\n",
    "        # Remove the chunk file after processing\n",
    "        os.remove(chunk)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Merge results into a single JSON object\n",
    "def merge_results(results):\n",
    "    # Combining all the transcribed text into a single JSON object\n",
    "    combined_result = {\"transcripts\": results}\n",
    "    \n",
    "    # Saving the combined result to a JSON file\n",
    "    with open('combined_transcript.json', 'w') as outfile:\n",
    "        json.dump(combined_result, outfile)\n",
    "\n",
    "    return combined_result\n",
    "\n",
    "# Define the transcribe function according to your API's specifications\n",
    "# Here's a placeholder for the 'transcribe' function.\n",
    "def transcribe(chunk_name):\n",
    "    # You'll replace this part with the actual API call\n",
    "    print(f\"Processing {chunk_name}...\")\n",
    "    # Simulate a transcription result\n",
    "    return f\"Transcription of {chunk_name}\"\n",
    "\n",
    "# Main function to handle the workflow\n",
    "def main(file_path):\n",
    "    chunks = split_audio(file_path)\n",
    "    results = process_chunks(chunks)\n",
    "    final_result = merge_results(results)\n",
    "    print(\"All chunks processed and merged successfully.\")\n",
    "    return final_result\n",
    "\n",
    "# Call the main function with the path to your mp3 file\n",
    "final_transcription = main(\"good_morning.mp3\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
